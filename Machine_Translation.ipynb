{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine_Translation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIqbPwIOYIxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import re\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_3YMGHJp3_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_text(filename):\n",
        "  file=open(filename, mode='rt', encoding='utf-8')\n",
        "  text = file.read()\n",
        "  file.close()\n",
        "  return text"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lqAb1AMqVL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split the text into sentences\n",
        "def to_lines(text):\n",
        "  sents = text.strip().split('\\n')\n",
        "  sents =[i.split('\\t') for i in sents]\n",
        "  #print(sents[:2])\n",
        "  return sents"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ1e_0M8qu4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data =read_text(\"deu.txt\")\n",
        "deu_eng=to_lines(data)\n",
        "deu_eng= array(deu_eng)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvjLIG2Eq8K0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To reduce the training time of the model I will be using only 50000 snetence pairs for training\n",
        "deu_eng = deu_eng[:50000,:2]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-yuPjFKsZ5G",
        "colab_type": "text"
      },
      "source": [
        "TEXT PREPROCESSING \n",
        "\n",
        "The data we work with is more often than not structured so there are certain thing we need to take care of before jumping to model building part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAVZPBnksUT0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "438dbb21-6051-4860-9dca-bf59933c9df2"
      },
      "source": [
        "deu_eng"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Go.', 'Geh.'],\n",
              "       ['Hi.', 'Hallo!'],\n",
              "       ['Hi.', 'Grüß Gott!'],\n",
              "       ...,\n",
              "       ['No one encouraged her.', 'Niemand ermutigte sie.'],\n",
              "       ['No one has that right.', 'Niemand hat dieses Recht.'],\n",
              "       ['No one has that right.', 'Dieses Recht hat niemand.']],\n",
              "      dtype='<U537')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNlNZXf7s0L_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "6c29345e-da8a-4966-ffa5-9ba0bf025957"
      },
      "source": [
        "# get rid of punctuation marks and also converting the text into lower case\n",
        "deu_eng[:,0] = [s.translate(str.maketrans('', '',string.punctuation)) for s in deu_eng[:,0]]\n",
        "deu_eng[:,1] = [s.translate(str.maketrans('','', string.punctuation)) for s in deu_eng[:,1]]\n",
        "deu_eng"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Go', 'Geh'],\n",
              "       ['Hi', 'Hallo'],\n",
              "       ['Hi', 'Grüß Gott'],\n",
              "       ...,\n",
              "       ['No one encouraged her', 'Niemand ermutigte sie'],\n",
              "       ['No one has that right', 'Niemand hat dieses Recht'],\n",
              "       ['No one has that right', 'Dieses Recht hat niemand']],\n",
              "      dtype='<U537')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f14eIdmitlUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "59a4431c-298c-4f44-8ca6-e49ad01cba67"
      },
      "source": [
        "for i in range(len(deu_eng)):\n",
        "  deu_eng[i,0] = deu_eng[i,0].lower()\n",
        "  deu_eng[i,1] = deu_eng[i,1].lower()\n",
        "\n",
        "deu_eng  "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['go', 'geh'],\n",
              "       ['hi', 'hallo'],\n",
              "       ['hi', 'grüß gott'],\n",
              "       ...,\n",
              "       ['no one encouraged her', 'niemand ermutigte sie'],\n",
              "       ['no one has that right', 'niemand hat dieses recht'],\n",
              "       ['no one has that right', 'dieses recht hat niemand']],\n",
              "      dtype='<U537')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSRzCl2CvlqO",
        "colab_type": "text"
      },
      "source": [
        "TEXT TO SEQUENCE CONVERSION\n",
        "\n",
        "A sequence to sequence model requires that we convert both the input and the output sentences into integer sequences of fixed length .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72W-5PHDvdpS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "ed263712-ee11-4399-8756-ced5e65327c4"
      },
      "source": [
        "eng_l =[]\n",
        "deu_l = []\n",
        "\n",
        "#populate lists with sentence lengths\n",
        "for i in deu_eng[:,0]:\n",
        "  eng_l.append(len(i.split()))\n",
        "\n",
        "for i in deu_eng[:,1]:\n",
        "  deu_l.append(len(i.split()))\n",
        "\n",
        "length_df=pd.DataFrame({'eng':eng_l, 'deu':deu_l})\n",
        "length_df.hist(bins=30)\n",
        "plt.show()   "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZqNq2Aqw50z",
        "colab_type": "text"
      },
      "source": [
        "Preparing token for both germn and english language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBP9YXJmws2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenization(lines):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(lines)\n",
        "  return tokenizer"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jNHYiUaRXFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "652a683f-7a92-409f-cf9b-4c2f2436ad71"
      },
      "source": [
        "eng_tokenizer = tokenization(deu_eng[:,0])\n",
        "deu_tokenizer = tokenization(deu_eng[:,1])\n",
        "eng_vocab_size= len(eng_tokenizer.word_index) +1\n",
        "eng_length =8\n",
        "\n",
        "deu_vocab_size = len(deu_tokenizer.word_index)+1\n",
        "deu_length=8\n",
        "print(eng_vocab_size)\n",
        "deu_vocab_size"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10329"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGpN1W7ZSLYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# padding to maximize sentence length as mentioned above\n",
        "\n",
        "def encode_sequences(tokenizer, length , lines):\n",
        "  seq= tokenizer.texts_to_sequences(lines)\n",
        "  #pad sequences with 0 value\n",
        "  seq = pad_sequences(seq, maxlen=length , padding='post')\n",
        "  return seq"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvjRKpemTiJc",
        "colab_type": "text"
      },
      "source": [
        "Splitting the data into training and testing for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU8jfmgPTYZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train ,test = train_test_split(deu_eng, test_size=0.2, random_state=12)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXiQdUBNT7Wi",
        "colab_type": "text"
      },
      "source": [
        "It's time to encode the sentences . We will encode German sentences as the input sequences and English sentences as the target sequences. This has to be done for both training and testing datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kXL3E6qT1cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX = encode_sequences(deu_tokenizer, deu_length,train[:,1])\n",
        "trainY= encode_sequences(eng_tokenizer, eng_length , train[:,0])\n",
        "\n",
        "testX = encode_sequences(deu_tokenizer, deu_length, test[:,1])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length\n",
        "                         , test[:,0])\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAfmR7WUVBtw",
        "colab_type": "text"
      },
      "source": [
        "Now comes the exiting part!\n",
        "\n",
        "We'll start off by defining our Seq2seq model architecture:\n",
        "\n",
        "->For the encoder, we will use an embedding layer and an LSTM layer\n",
        "\n",
        "->For the decoder, we will use another LSTM layer and dense layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFzMGK-PUy62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build NMT model\n",
        "def defnie_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
        "  model =Sequential()\n",
        "  model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
        "  model.add(LSTM(units))\n",
        "  model.add(RepeatVector(out_timesteps))\n",
        "  model.add(LSTM(units, return_sequences=True))\n",
        "  model.add(Dense(out_vocab, activation='softmax'))\n",
        "  return model\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBruaWrrXZh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = defnie_model(deu_vocab_size, eng_vocab_size,deu_length , eng_length , 512)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHhSxoRzXp7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rms = optimizers.RMSprop(lr=0.001)\n",
        "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG4COBdqYMUB",
        "colab_type": "text"
      },
      "source": [
        "The loss function, this is because the function allows us to use the target sequence as is, instead of the one-hot encoded format. \n",
        "## One hot encoding the target sequences using such as huge vocabulary might consume our system's entire memory.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtxU01iyYDaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "72a3033d-23ce-4628-b1dc-e2c890f3e4da"
      },
      "source": [
        "filename = 'model.h1.24_jan_20'\n",
        "checkpoint= ModelCheckpoint(filename, monitor='val_loss',verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# train model\n",
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0],trainY.shape[1],1), epochs=30, batch_size=512, validation_split=0.2, callbacks=[checkpoint],verbose=1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 3.4031\n",
            "Epoch 00001: val_loss improved from inf to 2.84726, saving model to model.h1.24_jan_20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 305s 5s/step - loss: 3.4031 - val_loss: 2.8473\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 2.7767\n",
            "Epoch 00002: val_loss improved from 2.84726 to 2.73137, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 302s 5s/step - loss: 2.7767 - val_loss: 2.7314\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 2.6235\n",
            "Epoch 00003: val_loss improved from 2.73137 to 2.57184, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 308s 5s/step - loss: 2.6235 - val_loss: 2.5718\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 2.4489\n",
            "Epoch 00004: val_loss improved from 2.57184 to 2.44081, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 350s 6s/step - loss: 2.4489 - val_loss: 2.4408\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 2.3125\n",
            "Epoch 00005: val_loss improved from 2.44081 to 2.35282, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 351s 6s/step - loss: 2.3125 - val_loss: 2.3528\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 2.1880\n",
            "Epoch 00006: val_loss improved from 2.35282 to 2.24973, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 354s 6s/step - loss: 2.1880 - val_loss: 2.2497\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 2.0743\n",
            "Epoch 00007: val_loss improved from 2.24973 to 2.16165, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 353s 6s/step - loss: 2.0743 - val_loss: 2.1616\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.9641\n",
            "Epoch 00008: val_loss improved from 2.16165 to 2.08903, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 348s 6s/step - loss: 1.9641 - val_loss: 2.0890\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.8599\n",
            "Epoch 00009: val_loss improved from 2.08903 to 2.00151, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 351s 6s/step - loss: 1.8599 - val_loss: 2.0015\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.7564\n",
            "Epoch 00010: val_loss improved from 2.00151 to 1.93850, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 349s 6s/step - loss: 1.7564 - val_loss: 1.9385\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.6590\n",
            "Epoch 00011: val_loss improved from 1.93850 to 1.87234, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 345s 5s/step - loss: 1.6590 - val_loss: 1.8723\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.5642\n",
            "Epoch 00012: val_loss improved from 1.87234 to 1.79982, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 342s 5s/step - loss: 1.5642 - val_loss: 1.7998\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.4749\n",
            "Epoch 00013: val_loss improved from 1.79982 to 1.75645, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 345s 5s/step - loss: 1.4749 - val_loss: 1.7565\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.3894\n",
            "Epoch 00014: val_loss improved from 1.75645 to 1.71020, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 342s 5s/step - loss: 1.3894 - val_loss: 1.7102\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.3083\n",
            "Epoch 00015: val_loss improved from 1.71020 to 1.67534, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 342s 5s/step - loss: 1.3083 - val_loss: 1.6753\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.2300\n",
            "Epoch 00016: val_loss improved from 1.67534 to 1.60817, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 339s 5s/step - loss: 1.2300 - val_loss: 1.6082\n",
            "Epoch 17/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.1545\n",
            "Epoch 00017: val_loss improved from 1.60817 to 1.57338, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 341s 5s/step - loss: 1.1545 - val_loss: 1.5734\n",
            "Epoch 18/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.0849\n",
            "Epoch 00018: val_loss improved from 1.57338 to 1.53527, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 347s 6s/step - loss: 1.0849 - val_loss: 1.5353\n",
            "Epoch 19/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.0137\n",
            "Epoch 00019: val_loss improved from 1.53527 to 1.50493, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 344s 5s/step - loss: 1.0137 - val_loss: 1.5049\n",
            "Epoch 20/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.9504\n",
            "Epoch 00020: val_loss improved from 1.50493 to 1.46635, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 344s 5s/step - loss: 0.9504 - val_loss: 1.4663\n",
            "Epoch 21/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.8875\n",
            "Epoch 00021: val_loss improved from 1.46635 to 1.43933, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 341s 5s/step - loss: 0.8875 - val_loss: 1.4393\n",
            "Epoch 22/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.8284\n",
            "Epoch 00022: val_loss improved from 1.43933 to 1.41805, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 342s 5s/step - loss: 0.8284 - val_loss: 1.4180\n",
            "Epoch 23/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.7700\n",
            "Epoch 00023: val_loss improved from 1.41805 to 1.39906, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 339s 5s/step - loss: 0.7700 - val_loss: 1.3991\n",
            "Epoch 24/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.7162\n",
            "Epoch 00024: val_loss improved from 1.39906 to 1.39459, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 340s 5s/step - loss: 0.7162 - val_loss: 1.3946\n",
            "Epoch 25/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.6652\n",
            "Epoch 00025: val_loss improved from 1.39459 to 1.36414, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 341s 5s/step - loss: 0.6652 - val_loss: 1.3641\n",
            "Epoch 26/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.6152\n",
            "Epoch 00026: val_loss improved from 1.36414 to 1.34751, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 337s 5s/step - loss: 0.6152 - val_loss: 1.3475\n",
            "Epoch 27/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.5704\n",
            "Epoch 00027: val_loss did not improve from 1.34751\n",
            "63/63 [==============================] - 323s 5s/step - loss: 0.5704 - val_loss: 1.3492\n",
            "Epoch 28/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.5263\n",
            "Epoch 00028: val_loss improved from 1.34751 to 1.33651, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 336s 5s/step - loss: 0.5263 - val_loss: 1.3365\n",
            "Epoch 29/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.4856\n",
            "Epoch 00029: val_loss improved from 1.33651 to 1.31386, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 337s 5s/step - loss: 0.4856 - val_loss: 1.3139\n",
            "Epoch 30/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.4482\n",
            "Epoch 00030: val_loss improved from 1.31386 to 1.30741, saving model to model.h1.24_jan_20\n",
            "INFO:tensorflow:Assets written to: model.h1.24_jan_20/assets\n",
            "63/63 [==============================] - 338s 5s/step - loss: 0.4482 - val_loss: 1.3074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7A1vZqvZlc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "e761ddc7-84da-4999-e11d-7bae3fba8dd2"
      },
      "source": [
        "model = load_model('model.h1.24_jan_20')\n",
        "testX.shape\n",
        "preds = model.predict_classes(testX.reshape((testX.shape[0], testX.shape[1])))\n",
        "testX.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-46-db8acfe516ea>:3: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zDflVqHaRdA",
        "colab_type": "text"
      },
      "source": [
        "These prediction are sequence of integers. We need to convert these integers to their corresponding words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUIQemhlaKuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word(n, tokenizer):\n",
        "      for word, index in tokenizer.word_index.items():\n",
        "          if index == n:\n",
        "              return word\n",
        "      return None "
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYTsebHTb9oG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9bc0d93-e706-439e-93d9-7e0a312a369a"
      },
      "source": [
        "preds.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz2v9KxfQFTo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "a4a0f159-a1a0-48c1-acfd-f78b4a42f988"
      },
      "source": [
        "for x in preds[:4]:\n",
        "  print(x)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   2 1132  155    0    0    0    0    0]\n",
            "[  7 399  17   0   0   0   0   0]\n",
            "[  7   7 796   0   0   0   0   0]\n",
            "[18 20  8 30  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5mk3wWFa9Tn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_text = []\n",
        "for i in preds:\n",
        "       temp = []\n",
        "       for j in range(len(i)):\n",
        "            t = get_word(i[j], eng_tokenizer)\n",
        "            if j > 0:\n",
        "                if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
        "                     temp.append('')\n",
        "                else:\n",
        "                     temp.append(t)\n",
        "            else:\n",
        "                   if (t == None):\n",
        "                          temp.append('')\n",
        "                   else:\n",
        "                          temp.append(t) \n",
        "\n",
        "       preds_text.append(' '.join(temp))"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fj6Wc4Nb_nn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuAHAI4qVLmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "fe041267-0b16-4915-e622-236d12f81cb8"
      },
      "source": [
        "pred_df.sample(15)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3093</th>\n",
              "      <td>have a beer with me</td>\n",
              "      <td>have a beer with me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7444</th>\n",
              "      <td>tom can walk</td>\n",
              "      <td>tom can run</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2656</th>\n",
              "      <td>go up these stairs</td>\n",
              "      <td>take a up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6099</th>\n",
              "      <td>what a strange man</td>\n",
              "      <td>what a strange man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1438</th>\n",
              "      <td>i sell computers</td>\n",
              "      <td>im drive the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4337</th>\n",
              "      <td>dont play dead</td>\n",
              "      <td>dont  nonsense</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5007</th>\n",
              "      <td>did tom forgive you</td>\n",
              "      <td>did tom forgive you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2319</th>\n",
              "      <td>we go tomorrow</td>\n",
              "      <td>were getting tomorrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2523</th>\n",
              "      <td>can you program in c</td>\n",
              "      <td>can you keep on up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4464</th>\n",
              "      <td>its not my fault</td>\n",
              "      <td>thats not my fault</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1587</th>\n",
              "      <td>hes an oceanographer</td>\n",
              "      <td>he is cranky</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2579</th>\n",
              "      <td>i need them</td>\n",
              "      <td>i need them</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9844</th>\n",
              "      <td>i was jealous</td>\n",
              "      <td>i was jealous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>send it by airmail</td>\n",
              "      <td>send the by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1667</th>\n",
              "      <td>cut it in half</td>\n",
              "      <td>is it in</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    actual                   predicted\n",
              "3093   have a beer with me      have a beer with me   \n",
              "7444          tom can walk            tom can run     \n",
              "2656    go up these stairs              take a up     \n",
              "6099    what a strange man      what a strange man    \n",
              "1438      i sell computers           im drive the     \n",
              "4337        dont play dead         dont  nonsense     \n",
              "5007   did tom forgive you     did tom forgive you    \n",
              "2319        we go tomorrow  were getting tomorrow     \n",
              "2523  can you program in c       can you keep on up   \n",
              "4464      its not my fault      thats not my fault    \n",
              "1587  hes an oceanographer           he is cranky     \n",
              "2579           i need them            i need them     \n",
              "9844         i was jealous          i was jealous     \n",
              "490     send it by airmail            send the by     \n",
              "1667        cut it in half               is it in     "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe_ZnyF4zkP9",
        "colab_type": "text"
      },
      "source": [
        "Even with a very simple Seq2Seq model, the results are pretty encouraging. We can improve on this performance easily by using a more sophisticated encoder-decoder model on a larger dataset.\n",
        "\n",
        "It can further improved if we use a dataset with longer sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg3Z4IPEVvAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}